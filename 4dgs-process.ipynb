{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b5cba2",
   "metadata": {},
   "source": [
    "# A Step By Step Workflow to Product 4DGS Volumetric Vdeio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33140b",
   "metadata": {},
   "source": [
    "## **Stage 0** - Function Definition & Initialization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa49f7",
   "metadata": {},
   "source": [
    "#### Function definition -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import torch\n",
    "from multiprocessing import freeze_support\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "\n",
    "def extract_frames(video_path, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_filename = os.path.join(output_dir, f\"{frame_count:05d}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    video_capture.release()\n",
    "    print(f\"Extracted {frame_count} frames from {video_path} to {output_dir}.\")\n",
    "\n",
    "def move_to_folder(src, dst_path, dst_name):\n",
    "    source = Path(rf\"{src}\")\n",
    "    ext = source.suffix\n",
    "    destination = Path(rf\"{dst_path}/{dst_name}{ext}\")\n",
    "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
    "    source.rename(destination)\n",
    "\n",
    "def rotate_images_in_folder(folder_path, opencv_rotate = cv2.ROTATE_90_CLOCKWISE):\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    rotated_count = 0\n",
    "\n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            img = cv2.imread(file_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                rotated_img = cv2.rotate(img, opencv_rotate)\n",
    "                \n",
    "                cv2.imwrite(file_path, rotated_img)\n",
    "                rotated_count += 1\n",
    "    \n",
    "    print(f\"Completed! Rotated {rotated_count} images in {folder_path}\")\n",
    "\n",
    "def convert_jpg_to_png(folder_path):\n",
    "    image_extensions = ['.jpg', '.jpeg']\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    converted_count = 0\n",
    "\n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            img = cv2.imread(file_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                rgba_img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "                \n",
    "                png_file_path = os.path.splitext(file_path)[0] + '.png'\n",
    "                cv2.imwrite(png_file_path, rgba_img)\n",
    "                \n",
    "                os.remove(file_path)\n",
    "                \n",
    "                converted_count += 1\n",
    "\n",
    "    print(f\"Completed! Converted {converted_count} images in {folder_path} to PNG format.\")\n",
    "\n",
    "def convert_png_to_jpg(folder_path):\n",
    "    image_extensions = ['.png']\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    converted_count = 0\n",
    "\n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            img = cv2.imread(file_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                rgba_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                png_file_path = os.path.splitext(file_path)[0] + '.jpg'\n",
    "                cv2.imwrite(png_file_path, rgba_img)\n",
    "                \n",
    "                os.remove(file_path)\n",
    "                \n",
    "                converted_count += 1\n",
    "\n",
    "    print(f\"Completed! Converted {converted_count} images in {folder_path} to JPG format.\")\n",
    "\n",
    "def detect_flash(images, pixel_position, pixel_size, channel_threshold: float = 5000, skip_frames: int = 150):\n",
    "    x, y = pixel_position\n",
    "\n",
    "    start_frame = -1\n",
    "    end_frame = -1\n",
    "\n",
    "    last_roi = cv2.imread(images[0])[y-pixel_size:y+pixel_size, x-pixel_size:x+pixel_size]\n",
    "\n",
    "    plot_size = (1, 1)\n",
    "\n",
    "    plt.figure(figsize=plot_size)\n",
    "    plt.imshow(cv2.cvtColor(last_roi, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('ROI Calculation Preview')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    i = 0\n",
    "    while i < len(images):\n",
    "        image_path = images[i]\n",
    "        curr_roi = cv2.imread(image_path)[y-pixel_size:y+pixel_size, x-pixel_size:x+pixel_size]\n",
    "        curr_bgr_mean = np.mean(curr_roi, axis=(0, 1))\n",
    "        last_bgr_mean = np.mean(last_roi, axis=(0, 1))\n",
    "        r_diff = curr_bgr_mean[2] - last_bgr_mean[2]\n",
    "        r_diff_cube = r_diff * r_diff * r_diff\n",
    "\n",
    "        last_roi = curr_roi\n",
    "        \n",
    "        if r_diff_cube > channel_threshold:\n",
    "            if start_frame >= 0:\n",
    "                plt.figure(figsize=plot_size)\n",
    "                plt.imshow(cv2.cvtColor(curr_roi, cv2.COLOR_BGR2RGB))\n",
    "                plt.title('End Frame Preview')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "                end_frame = i\n",
    "                break\n",
    "\n",
    "            if start_frame < 0:\n",
    "                plt.figure(figsize=plot_size)\n",
    "                plt.imshow(cv2.cvtColor(curr_roi, cv2.COLOR_BGR2RGB))\n",
    "                plt.title('Start Frame Preview')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "                start_frame = i\n",
    "                last_roi = cv2.imread(images[i + skip_frames])[y-pixel_size:y+pixel_size, x-pixel_size:x+pixel_size]\n",
    "                i += skip_frames\n",
    "                continue\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "        \n",
    "\n",
    "    return start_frame, end_frame\n",
    "    \n",
    "def get_pixel_position(event, x, y, flags, param):\n",
    "    scale_factor, clicked_flag, pix_x, pix_y = param\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        original_x = int(x / scale_factor)\n",
    "        original_y = int(y / scale_factor)\n",
    "        \n",
    "        pix_x[0] = original_x\n",
    "        pix_y[0] = original_y\n",
    "        \n",
    "        clicked_flag[0] = True\n",
    "\n",
    "def roi_pixel_selection(image_path):\n",
    "    # Window dimensions\n",
    "    MAX_WIDTH = 1000\n",
    "    MAX_HEIGHT = 800\n",
    "\n",
    "    clicked_flag = [False]\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    original_height, original_width = img.shape[:2]\n",
    "\n",
    "    scale_factor = min(MAX_WIDTH / original_width, MAX_HEIGHT / original_height)\n",
    "    scale_factor = min(1.0, scale_factor) \n",
    "\n",
    "    display_width = int(original_width * scale_factor)\n",
    "    display_height = int(original_height * scale_factor)\n",
    "\n",
    "    display_img = cv2.resize(img, (display_width, display_height))\n",
    "\n",
    "    window_name = 'Click on Image to Select ROI Pixel'\n",
    "    cv2.namedWindow(window_name)\n",
    "\n",
    "    roi_pix_x = [-1]\n",
    "    roi_pix_y = [-1]\n",
    "\n",
    "    cv2.setMouseCallback(window_name, get_pixel_position, (scale_factor, clicked_flag, roi_pix_x, roi_pix_y))\n",
    "\n",
    "    cv2.imshow(window_name, display_img)\n",
    "\n",
    "    while not clicked_flag[0]:\n",
    "        if cv2.waitKey(1) != -1 or cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if roi_pix_x[0] != -1 and roi_pix_y[0] != -1:\n",
    "        return (roi_pix_x[0], roi_pix_y[0])\n",
    "    \n",
    "def rs_align_campos(rs_path, import_path):\n",
    "    cmd = [\n",
    "        rs_path, \"-headless\",\n",
    "        \"-addFolder\", str(import_path),\n",
    "        \"-align\",\n",
    "        \"-exportXMP\",\n",
    "        \"-quit\"\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error running command: {' '.join(cmd)}\")\n",
    "        print(f\"stdout: {result.stdout}\")\n",
    "        print(f\"stderr: {result.stderr}\")\n",
    "        raise RuntimeError(f\"COLMAP command failed with return code {result.returncode}\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def rs_align_xmp(rs_path, import_path, export_path, xml_path):\n",
    "    cmd = [\n",
    "        rs_path, \"-headless\",\n",
    "        \"-addFolder\", str(import_path),\n",
    "        \"-align\",\n",
    "        \"-exportRegistration\", f\"{str(export_path)}/placeholder.txt\", str(xml_path),\n",
    "        \"-quit\"\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error running command: {' '.join(cmd)}\")\n",
    "        print(f\"stdout: {result.stdout}\")\n",
    "        print(f\"stderr: {result.stderr}\")\n",
    "        raise RuntimeError(f\"COLMAP command failed with return code {result.returncode}\")\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60242a07",
   "metadata": {},
   "source": [
    "#### Global path definitions -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for raw videos\n",
    "videos_by_view = r\"C:\\repos\\_DATASETS_\\4dgs-250729\\gs-take-00\\views\"\n",
    "\n",
    "# Define path for soar mesh raw color feed\n",
    "soar_sequence = r\"C:\\repos\\_DATASETS_\\4dgs-250729\\gs-take-00\\take1\"\n",
    "\n",
    "# Define the output path for training dataset\n",
    "output_dataset = r\"C:\\repos\\_DATASETS_\\4dgs-250729\\gs-take-00\\out\"\n",
    "\n",
    "\n",
    "stage_1_rgb_sequence_by_view = rf\"{output_dataset}\\rgb_sequence_by_view\"\n",
    "rs_training_dataset = rf\"{output_dataset}\\rs_train\"\n",
    "postshot_training_dataset = rf\"{output_dataset}\\postshot_train\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed756252",
   "metadata": {},
   "source": [
    "#### Dependencies path definitions -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path to RobustVideoMatting\n",
    "rvm_path = r\"C:\\repos\\RobustVideoMatting\"\n",
    "\n",
    "sys.path.append(rvm_path)\n",
    "model = torch.hub.load(\"PeterL1n/RobustVideoMatting\", \"mobilenetv3\").cuda()\n",
    "convert_video = torch.hub.load(\"PeterL1n/RobustVideoMatting\", \"converter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f6b77",
   "metadata": {},
   "source": [
    "#### Raw dataset extension definitions -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3fc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv', '*.flv', '*.webm', '*.m4v', '*.3gp', '*.mpg', '*.mpeg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f02e9",
   "metadata": {},
   "source": [
    "## **Stage 1** - RGB Sequence Extraction from Raw Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaca2db",
   "metadata": {},
   "source": [
    "### Organize soar raw color feeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ca873",
   "metadata": {},
   "source": [
    "#### Report data found -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc09c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "soar_frames_by_view = []\n",
    "images = []\n",
    "for ext in image_extensions:\n",
    "    images.extend(glob.glob(os.path.join(soar_sequence, ext)))\n",
    "\n",
    "images = sorted(images)\n",
    "\n",
    "print(f\"Found {len(images)} images in {soar_sequence}\")\n",
    "\n",
    "view_names = []\n",
    "i = -1\n",
    "\n",
    "for image_path in images:\n",
    "    filename = os.path.basename(image_path)\n",
    "    \n",
    "    parts = filename.split('.')\n",
    "    view_name = parts[0]\n",
    "    \n",
    "    if view_name not in view_names:\n",
    "        view_names.append(view_name)\n",
    "        soar_frames_by_view.append([rf\"{image_path}\"])\n",
    "        i += 1\n",
    "    else:\n",
    "        soar_frames_by_view[i].append(rf\"{image_path}\")\n",
    "\n",
    "for i, view in enumerate(soar_frames_by_view):\n",
    "    print(f\"View: {i}, Name: {view_names[i]}, Number of frames: {len(view)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f41388",
   "metadata": {},
   "source": [
    "#### Image rotation if needed -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603487bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_images_in_folder(soar_sequence, cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e98a7f",
   "metadata": {},
   "source": [
    "#### Organize reported soar data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soar_rgb_sequence_folders = []\n",
    "for i in range(len(soar_frames_by_view)):\n",
    "    folder_name = f\"soar_view_{i}\"\n",
    "    output_path = os.path.join(stage_1_rgb_sequence_by_view, folder_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    soar_rgb_sequence_folders.append(output_path)\n",
    "\n",
    "for i, frame in enumerate(soar_frames_by_view):\n",
    "    for j, view_image in enumerate(frame):\n",
    "        if view_image:\n",
    "            move_to_folder(view_image, soar_rgb_sequence_folders[i], f\"{j:05d}\")\n",
    "\n",
    "print(\"Organized soar raw color feeds into respective folders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdccfc7",
   "metadata": {},
   "source": [
    "### Organize raw video captures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29776589",
   "metadata": {},
   "source": [
    "#### Report data found -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "for ext in video_extensions:\n",
    "    videos.extend(glob.glob(os.path.join(videos_by_view, ext)))\n",
    "\n",
    "videos = sorted(videos)\n",
    "\n",
    "print(f\"Found {len(videos)} videos in {videos_by_view}:\")\n",
    "for video in videos:\n",
    "    print(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c842641",
   "metadata": {},
   "source": [
    "#### Extract frames and organize -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34598cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, video in enumerate(videos):\n",
    "    print(f\"Processing video {i+1}/{len(videos)}: {video}\")\n",
    "    output_dir = os.path.join(stage_1_rgb_sequence_by_view, f\"recorded_{i:02d}\")\n",
    "    extract_frames(video, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7d481",
   "metadata": {},
   "source": [
    "#### Data preview. Stage 1 --> Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_sequence_by_view_folders = [d for d in os.listdir(stage_1_rgb_sequence_by_view) if os.path.isdir(os.path.join(stage_1_rgb_sequence_by_view, d))]\n",
    "rgb_sequence_by_view_folders = sorted(rgb_sequence_by_view_folders)\n",
    "rgb_sequence_by_view_folders = [os.path.join(stage_1_rgb_sequence_by_view, folder) for folder in rgb_sequence_by_view_folders]\n",
    "stage_2_rgb_sequence_by_view_folders = rgb_sequence_by_view_folders\n",
    "\n",
    "for i, folder in enumerate(stage_2_rgb_sequence_by_view_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(folder, ext)))\n",
    "\n",
    "    images = sorted(images)\n",
    "    print(f\"View: {i}, Path: {folder}, Number of frames: {len(images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9646cad",
   "metadata": {},
   "source": [
    "## **Stage 2** - Frame Synchronization & Alpha Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d244a2e",
   "metadata": {},
   "source": [
    "#### ROI selection -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "led_roi = []\n",
    "\n",
    "for i, folder in enumerate(stage_2_rgb_sequence_by_view_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(folder, ext)))\n",
    "    images = sorted(images)\n",
    "\n",
    "    led_roi.append(roi_pixel_selection(images[0]))\n",
    "\n",
    "for i, roi in enumerate(led_roi):\n",
    "    if roi is not None:\n",
    "        print(f\"View: {i}, ROI pixel position: {roi}\")\n",
    "    else:\n",
    "        print(\"No ROI selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a16053",
   "metadata": {},
   "source": [
    "#### Flash frame detection -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d35d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_frame_locs = []\n",
    "frame_count = 900 # init approximate frame count\n",
    "for i, view_folder in enumerate(stage_2_rgb_sequence_by_view_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(view_folder, ext)))\n",
    "    images = sorted(images)\n",
    "    \n",
    "    start, end = detect_flash(images, led_roi[i], 10, 10000, frame_count - 90)\n",
    "    frame_count = end - start\n",
    "    crop_frame_locs.append([start, end])\n",
    "    if (start != -1 and end != -1):\n",
    "        print(f\"View: {i}: Count: {end - start}, from({os.path.basename(images[start])}) to({os.path.basename(images[end])})\")\n",
    "    elif(start == -1):\n",
    "        frame_count = 900\n",
    "        print(f\"View: {i}, Start: Not Found, End: Not Found\")\n",
    "    elif(end == -1):\n",
    "        frame_count = 900\n",
    "        print(f\"View: {i}, Start: {os.path.basename(images[start])}, End: Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a4f56",
   "metadata": {},
   "source": [
    "#### Synchronize frames -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5cf8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, view_folder in enumerate(stage_2_rgb_sequence_by_view_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(view_folder, ext)))\n",
    "    images = sorted(images)\n",
    "\n",
    "    start, end = crop_frame_locs[i]\n",
    "\n",
    "    for j in range(0, start):\n",
    "        os.remove(images[j])\n",
    "\n",
    "    for k in range(end + 1, len(images)):\n",
    "        os.remove(images[k])\n",
    "\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(view_folder, ext)))\n",
    "    images = sorted(images)\n",
    "    # raname images after removing the first frames name format: 00000.jpg, 00001.jpg, ...\n",
    "    for j, image in enumerate(images):\n",
    "        new_name = f\"{j:05d}.jpg\"\n",
    "        new_path = os.path.join(view_folder, new_name)\n",
    "        os.rename(image, new_path)\n",
    "\n",
    "    print(f\"View: {i}, Updated frames: {len(images)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc37fda",
   "metadata": {},
   "source": [
    "#### Save single frame for camera data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training data - first frame\n",
    "\n",
    "frames_by_views = []\n",
    "for i, view_folder in enumerate(stage_2_rgb_sequence_by_view_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(view_folder, ext)))\n",
    "\n",
    "    images = sorted(images)\n",
    "    \n",
    "    frames_by_views.append(images)\n",
    "\n",
    "first_frame_folder = os.path.join(rs_training_dataset, \"frame_0\")\n",
    "for view_number in range(len(frames_by_views)):\n",
    "    move_to_folder(frames_by_views[view_number][0], first_frame_folder, f\"{view_number:05d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62012827",
   "metadata": {},
   "source": [
    "#### Convert to png if RGBA is needed -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_jpg_to_png(first_frame_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c53edc3",
   "metadata": {},
   "source": [
    "#### RGB sequence matting -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e4699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove background\n",
    "\n",
    "temp_folder = rf\"{output_dataset}\\temp\"\n",
    "if not os.path.exists(temp_folder):\n",
    "    os.makedirs(temp_folder)\n",
    "\n",
    "frames_nobg_by_view_folders = []\n",
    "\n",
    "for i, view_folder in enumerate(stage_2_rgb_sequence_by_view_folders):\n",
    "    temp_sequence_folder = os.path.join(temp_folder, f\"view_{i:02d}\")\n",
    "    convert_video(\n",
    "        model,                           # The loaded model, can be on any device (cpu or cuda).\n",
    "        input_source=view_folder,        # A video file or an image sequence directory.\n",
    "        downsample_ratio=None,           # [Optional] If None, make downsampled max size be 512px.\n",
    "        output_type='png_sequence',             # Choose \"video\" or \"png_sequence\"\n",
    "        output_composition=temp_sequence_folder,    # File path if video; directory path if png sequence.\n",
    "        #output_alpha=f\"{output}/pha.mp4\",          # [Optional] Output the raw alpha prediction.\n",
    "        #output_foreground=f\"{output}/fgr.mp4\",     # [Optional] Output the raw foreground prediction.\n",
    "        #output_video_mbps=4,             # Output video mbps. Not needed for png sequence.\n",
    "        seq_chunk=15,                    # Process n frames at once for better parallelism.\n",
    "        num_workers=5,                   # Only for image sequence input. Reader threads.\n",
    "        progress=True                    # Print conversion progress.\n",
    "    )\n",
    "    frames_nobg_by_view_folders.append(temp_sequence_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c375e",
   "metadata": {},
   "source": [
    "#### Organize RGBA sequence -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = rf\"{output_dataset}\\temp\"\n",
    "\n",
    "frames_nobg_by_view_folders = [d for d in os.listdir(temp_folder) if os.path.isdir(os.path.join(temp_folder, d))]\n",
    "frames_nobg_by_view_folders = sorted(frames_nobg_by_view_folders)\n",
    "frames_nobg_by_view_folders = [os.path.join(temp_folder, folder) for folder in frames_nobg_by_view_folders]\n",
    "\n",
    "frames_nobg_by_views = []\n",
    "\n",
    "for i, folder in enumerate(frames_nobg_by_view_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(folder, ext)))\n",
    "\n",
    "    images = sorted(images)\n",
    "    frames_nobg_by_views.append(images)\n",
    "\n",
    "for i, view in enumerate(frames_nobg_by_views):\n",
    "    print(f\"View: {i}, Number of frames: {len(view)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27f73b",
   "metadata": {},
   "source": [
    "#### Crop synchronized RGBA sequence -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_num_of_frames = min(len(view) for view in frames_nobg_by_views)\n",
    "\n",
    "for i, frames_by_view in enumerate(frames_nobg_by_views):\n",
    "    for j, frame in enumerate(frames_by_view):\n",
    "        if j < min_num_of_frames:\n",
    "            dst = os.path.join(rs_training_dataset, f\"frame_{j:05d}\")\n",
    "            move_to_folder(frame, dst, f\"{i:05d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef028b",
   "metadata": {},
   "source": [
    "#### Data preview. Stage 2 --> Stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229deaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_3_frame_folders = [d for d in os.listdir(rs_training_dataset) if os.path.isdir(os.path.join(rs_training_dataset, d))]\n",
    "stage_3_frame_folders = sorted(stage_3_frame_folders)\n",
    "stage_3_frame_folders = [os.path.join(rs_training_dataset, folder) for folder in stage_3_frame_folders]\n",
    "\n",
    "for i, folder in enumerate(stage_3_frame_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(folder, ext)))\n",
    "\n",
    "    images = sorted(images)\n",
    "    print(f\"Frame: {folder}, Views: {len(images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7a7a7",
   "metadata": {},
   "source": [
    "## **Stage 3** - Volumetrization & Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b03469",
   "metadata": {},
   "source": [
    "#### Define paths to RealityScan files -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33574238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to RealityScan.exe\n",
    "rs_exe_path = r\"C:\\Program Files\\Epic Games\\RealityScan_2.0\\RealityScan.exe\"\n",
    "\n",
    "# Path to Colmap data export profile\n",
    "rx_export_xml = r\"C:\\repos\\_DATASETS_\\4dgs-250729\\gs-take-00\\colmap_profile_img_rgba_wxmp.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc7b06",
   "metadata": {},
   "source": [
    "#### Extract camera intrinct & extrinct data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcf69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame = stage_3_frame_folders[0]\n",
    "\n",
    "if (rs_align_campos(rs_exe_path, first_frame)):\n",
    "    print(f\"First frame {first_frame} aligned successfully.\")\n",
    "\n",
    "    xmp_files = []\n",
    "    \n",
    "    xmp_files.extend(glob.glob(os.path.join(first_frame, \"*.xmp\")))\n",
    "\n",
    "    if not xmp_files:\n",
    "        print(f\"No XMP files found in {first_frame}, skipping subsequent frames alignment.\")\n",
    "        exit(1)\n",
    "\n",
    "    for xmp_file in xmp_files:\n",
    "        for frame_folder in stage_3_frame_folders[1:]:\n",
    "            shutil.copy2(xmp_file, frame_folder)\n",
    "        \n",
    "        print(f\"Copied XMP file {xmp_file} to all frames.\")\n",
    "else:\n",
    "    print(f\"Failed to align first frame {first_frame.name}. Exiting.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a7c91",
   "metadata": {},
   "source": [
    "#### Construct sparse point model -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process subsequent frames\n",
    "for i, images_path in enumerate(stage_3_frame_folders[1:]):\n",
    "    \n",
    "    export_path = rf\"{postshot_training_dataset}/frame_{i:05d}\"\n",
    "    if not os.path.exists(export_path):\n",
    "        os.makedirs(export_path)\n",
    "\n",
    "    try:\n",
    "        if rs_align_xmp(rs_exe_path, images_path, export_path, rx_export_xml):\n",
    "            print(f\"Frame {i} aligned successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to align frame {frame_folder.name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing frame {frame_folder.name}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448478a",
   "metadata": {},
   "source": [
    "## Below is for testing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_brightness_contrast(reference_image_path):\n",
    "    image = cv2.imread(reference_image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to grayscale for global statistics\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate brightness (mean intensity)\n",
    "    target_brightness = np.mean(gray)\n",
    "    \n",
    "    # Calculate contrast (standard deviation)\n",
    "    target_contrast = np.std(gray)\n",
    "    \n",
    "    # Calculate per-channel statistics for color correction\n",
    "    channel_means = [np.mean(image_rgb[:, :, i]) for i in range(3)]\n",
    "    channel_stds = [np.std(image_rgb[:, :, i]) for i in range(3)]\n",
    "    \n",
    "    brightness_contrast_data = {\n",
    "        'target_brightness': target_brightness,\n",
    "        'target_contrast': target_contrast,\n",
    "        'channel_means': channel_means,  # [R, G, B]\n",
    "        'channel_stds': channel_stds,    # [R, G, B]\n",
    "        'reference_image_path': reference_image_path\n",
    "    }\n",
    "    \n",
    "    print(f\"Reference image: {reference_image_path}\")\n",
    "    print(f\"Target brightness: {target_brightness:.2f}\")\n",
    "    print(f\"Target contrast: {target_contrast:.2f}\")\n",
    "    print(f\"Channel means (R,G,B): [{channel_means[0]:.2f}, {channel_means[1]:.2f}, {channel_means[2]:.2f}]\")\n",
    "    print(f\"Channel stds (R,G,B): [{channel_stds[0]:.2f}, {channel_stds[1]:.2f}, {channel_stds[2]:.2f}]\")\n",
    "    \n",
    "    return brightness_contrast_data\n",
    "\n",
    "def apply_brightness_contrast(input_image_path, brightness_contrast_data):\n",
    "    # Load the input image\n",
    "    image = cv2.imread(input_image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get target values\n",
    "    target_brightness = brightness_contrast_data['target_brightness']\n",
    "    target_contrast = brightness_contrast_data['target_contrast']\n",
    "    target_means = brightness_contrast_data['channel_means']\n",
    "    target_stds = brightness_contrast_data['channel_stds']\n",
    "    \n",
    "    # Calculate current image statistics\n",
    "    current_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    current_brightness = np.mean(current_gray)\n",
    "    current_contrast = np.std(current_gray)\n",
    "    \n",
    "    current_means = [np.mean(image_rgb[:, :, i]) for i in range(3)]\n",
    "    current_stds = [np.std(image_rgb[:, :, i]) for i in range(3)]\n",
    "    \n",
    "    # Create corrected image\n",
    "    corrected_image = image_rgb.copy().astype(np.float32)\n",
    "    \n",
    "    # Apply correction to each channel\n",
    "    for channel in range(3):\n",
    "        if current_stds[channel] > 0:  # Avoid division by zero\n",
    "            # Normalize current channel to have mean=0, std=1\n",
    "            corrected_image[:, :, channel] = (corrected_image[:, :, channel] - current_means[channel]) / current_stds[channel]\n",
    "            \n",
    "            # Scale to target std and shift to target mean\n",
    "            corrected_image[:, :, channel] = corrected_image[:, :, channel] * target_stds[channel] + target_means[channel]\n",
    "    \n",
    "    # Clip values to valid range [0, 255]\n",
    "    corrected_image = np.clip(corrected_image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert back to BGR for saving\n",
    "    corrected_bgr = cv2.cvtColor(corrected_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Replace the original image\n",
    "    cv2.imwrite(input_image_path, corrected_bgr)\n",
    "    \n",
    "    # Print statistics\n",
    "    corrected_gray = cv2.cvtColor(corrected_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    final_brightness = np.mean(corrected_gray)\n",
    "    final_contrast = np.std(corrected_gray)\n",
    "    \n",
    "    print(f\"\\nProcessed: {input_image_path}\")\n",
    "    print(f\"Brightness: {current_brightness:.2f} -> {final_brightness:.2f} (Target: {target_brightness:.2f})\")\n",
    "    print(f\"Contrast: {current_contrast:.2f} -> {final_contrast:.2f} (Target: {target_contrast:.2f})\")\n",
    "    print(f\"✓ Original image replaced with corrected version\")\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Step 1: Extract brightness/contrast data from reference image\n",
    "reference_path = r\"C:\\Users\\otuga\\Desktop\\test_frames\\1.jpg\"\n",
    "bc_data = extract_brightness_contrast(reference_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "\n",
    "image_paths = []\n",
    "for ext in image_extensions:\n",
    "    image_paths.extend(glob.glob(os.path.join(r\"C:\\Users\\otuga\\Desktop\\test_frames\", ext)))\n",
    "\n",
    "for img_path in image_paths:\n",
    "    apply_brightness_contrast(img_path, bc_data)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"\\n✓ All images have been processed and replaced with corrected versions!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

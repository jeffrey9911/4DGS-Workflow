{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca7751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3bfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "from multiprocessing import freeze_support\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def extract_frames(video_path, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_filename = os.path.join(output_dir, f\"{frame_count:05d}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    video_capture.release()\n",
    "    print(f\"Extracted {frame_count} frames from {video_path} to {output_dir}.\")\n",
    "\n",
    "def move_to_folder(src, dst_path, dst_name):\n",
    "    source = Path(rf\"{src}\")\n",
    "    destination = Path(rf\"{dst_path}/{dst_name}\")\n",
    "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
    "    source.rename(destination)\n",
    "\n",
    "def rotate_images_in_folder(folder_path):\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    rotated_count = 0\n",
    "\n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            img = cv2.imread(file_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                # Rotate the image -90 degrees (counterclockwise)\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "                \n",
    "                # Save the rotated image, overwriting the original\n",
    "                cv2.imwrite(file_path, rotated_img)\n",
    "                rotated_count += 1\n",
    "                #print(f\"Rotated: {file}\")\n",
    "    \n",
    "    print(f\"Completed! Rotated {rotated_count} images in {folder_path}\")\n",
    "\n",
    "def detect_hsv_red_change(images, pixel_position, pixel_size, saturation_threshold: float = 30) -> int:\n",
    "    baseline_hsv = {}\n",
    "    \n",
    "    x, y = pixel_position\n",
    "    h_sum = s_sum = v_sum = 0.0\n",
    "    \n",
    "    for i, image_path in enumerate(images[:5]):\n",
    "        img = cv2.imread(image_path)\n",
    "        if y < img.shape[0] and x < img.shape[1]:\n",
    "            pixel_bgr = img[y-pixel_size:y+pixel_size, x-pixel_size:x+pixel_size]\n",
    "            pixel_hsv = cv2.cvtColor(pixel_bgr, cv2.COLOR_BGR2HSV)[0, 0]\n",
    "            h, s, v = pixel_hsv\n",
    "            h_sum += float(h)\n",
    "            s_sum += float(s)\n",
    "            v_sum += float(v)\n",
    "    \n",
    "    baseline_hsv = {\n",
    "        'h': h_sum / 5,\n",
    "        's': s_sum / 5,\n",
    "        'v': v_sum / 5\n",
    "    }\n",
    "\n",
    "    start_frame_index = -1\n",
    "    \n",
    "    for frame_idx, image_path in enumerate(images):\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        x, y = pixel_position\n",
    "            \n",
    "        if y >= image.shape[0] or x >= image.shape[1]:\n",
    "            continue\n",
    "        \n",
    "        pixel_bgr = image[y-pixel_size:y+pixel_size, x-pixel_size:x+pixel_size]\n",
    "        h, s, v = cv2.cvtColor(pixel_bgr, cv2.COLOR_BGR2HSV)[0, 0]\n",
    "        \n",
    "        is_red_hue = (h <= 10) or (h >= 170)\n",
    "        saturation_increase = s - baseline_hsv['s']\n",
    "        brightness_increase = v - baseline_hsv['v']\n",
    "        \n",
    "        if (is_red_hue and \n",
    "            saturation_increase > saturation_threshold and \n",
    "            brightness_increase > 10):\n",
    "            \n",
    "            start_frame_index = frame_idx\n",
    "            break\n",
    "\n",
    "    stop_frame_index = -1\n",
    "    if start_frame_index != -1:\n",
    "        for frame_idx, image_path in enumerate(images[start_frame_index+150:]):\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            x, y = pixel_position\n",
    "                \n",
    "            if y >= image.shape[0] or x >= image.shape[1]:\n",
    "                continue\n",
    "            \n",
    "            pixel_bgr = image[y-pixel_size:y+pixel_size, x-pixel_size:x+pixel_size]\n",
    "            h, s, v = cv2.cvtColor(pixel_bgr, cv2.COLOR_BGR2HSV)[0, 0]\n",
    "            \n",
    "            is_red_hue = (h <= 10) or (h >= 170)\n",
    "            saturation_increase = s - baseline_hsv['s']\n",
    "            brightness_increase = v - baseline_hsv['v']\n",
    "            \n",
    "            if (is_red_hue and \n",
    "                saturation_increase > saturation_threshold and \n",
    "                brightness_increase > 10):\n",
    "                \n",
    "                stop_frame_index = frame_idx\n",
    "                break\n",
    "            \n",
    "    if start_frame_index != -1 and stop_frame_index != -1:\n",
    "        return [start_frame_index, stop_frame_index + start_frame_index + 150]\n",
    "    return -1\n",
    "\n",
    "def rs_align_with_xmp(rs_path, import_path, export_path, xml_path):\n",
    "    cmd = [\n",
    "        rs_path, \"-headless\",\n",
    "        \"-addFolder\", str(import_path),\n",
    "        \"-align\",\n",
    "        \"-exportRegistration\", f\"{str(export_path)}/placeholder.txt\", str(xml_path),\n",
    "        \"-quit\"\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error running command: {' '.join(cmd)}\")\n",
    "        print(f\"stdout: {result.stdout}\")\n",
    "        print(f\"stderr: {result.stderr}\")\n",
    "        raise RuntimeError(f\"COLMAP command failed with return code {result.returncode}\")\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f718b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_by_view = r\"N:\\shared\\yaojie\\250728-Capture\\views-raw-9\"\n",
    "soar_sequence = r\"N:\\shared\\yaojie\\250728-Capture\\raw-col\"\n",
    "\n",
    "rgb_sequence_by_view_output = r\"N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\"\n",
    "frames_to_train = r\"N:\\shared\\yaojie\\250728-Capture\\to_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc09c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7424 images in N:\\shared\\yaojie\\250728-Capture\\raw-col\n",
      "View: 0, Name: take3_175889972_000070704912, Number of images: 928\n",
      "View: 1, Name: take3_175889972_000079504912, Number of images: 928\n",
      "View: 2, Name: take3_175889972_000123120312, Number of images: 928\n",
      "View: 3, Name: take3_175889972_000147211512, Number of images: 928\n",
      "View: 4, Name: take3_175889972_000927310812, Number of images: 928\n",
      "View: 5, Name: take3_175889972_000984794512, Number of images: 928\n",
      "View: 6, Name: take3_175889972_001420795012, Number of images: 928\n",
      "View: 7, Name: take3_175889972_001430695012, Number of images: 928\n"
     ]
    }
   ],
   "source": [
    "image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "\n",
    "soar_frames_by_view = []\n",
    "images = []\n",
    "for ext in image_extensions:\n",
    "    images.extend(glob.glob(os.path.join(soar_sequence, ext)))\n",
    "\n",
    "images = sorted(images)\n",
    "\n",
    "print(f\"Found {len(images)} images in {soar_sequence}\")\n",
    "\n",
    "view_names = []\n",
    "i = -1\n",
    "\n",
    "for image_path in images:\n",
    "    filename = os.path.basename(image_path)\n",
    "    \n",
    "    parts = filename.split('.')\n",
    "    view_name = parts[0]\n",
    "    \n",
    "    if view_name not in view_names:\n",
    "        view_names.append(view_name)\n",
    "        soar_frames_by_view.append([rf\"{image_path}\"])\n",
    "        i += 1\n",
    "    else:\n",
    "        soar_frames_by_view[i].append(rf\"{image_path}\")\n",
    "\n",
    "for i, view in enumerate(soar_frames_by_view):\n",
    "    print(f\"View: {i}, Name: {view_names[i]}, Number of images: {len(view)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc3d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soar_rgb_sequence_folders = []\n",
    "for i in range(len(soar_frames_by_view)):\n",
    "    folder_name = f\"soar_view_{i}\"\n",
    "    output_path = os.path.join(rgb_sequence_by_view_output, folder_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    soar_rgb_sequence_folders.append(output_path)\n",
    "\n",
    "for i, frame in enumerate(soar_frames_by_view):\n",
    "    for j, view_image in enumerate(frame):\n",
    "        if view_image:\n",
    "            move_to_folder(view_image, soar_rgb_sequence_folders[i], f\"{j:05d}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed.\n",
    "for view in soar_rgb_sequence_folders:\n",
    "    rotate_images_in_folder(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d9937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 videos:\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281413_C011.mov\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C008 2.mov\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C008.mov\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C011.mov\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281415_C008.mov\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\GX010031.MP4\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\GX010127.MP4\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\a cam001_07281413_C003.mov\n",
      "N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\temp_video_for_share.mp4\n",
      "Processing video 0/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281413_C011.mov\n",
      "Extracted 2144 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281413_C011.mov to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_00.\n",
      "Processing video 1/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C008 2.mov\n",
      "Extracted 2024 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C008 2.mov to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_01.\n",
      "Processing video 2/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C008.mov\n",
      "Extracted 2120 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C008.mov to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_02.\n",
      "Processing video 3/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C011.mov\n",
      "Extracted 2118 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281414_C011.mov to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_03.\n",
      "Processing video 4/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281415_C008.mov\n",
      "Extracted 2097 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\A001_07281415_C008.mov to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_04.\n",
      "Processing video 5/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\GX010031.MP4\n",
      "Extracted 2076 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\GX010031.MP4 to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_05.\n",
      "Processing video 6/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\GX010127.MP4\n",
      "Extracted 2031 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\GX010127.MP4 to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_06.\n",
      "Processing video 7/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\a cam001_07281413_C003.mov\n",
      "Extracted 2020 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\a cam001_07281413_C003.mov to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_07.\n",
      "Processing video 8/9: N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\temp_video_for_share.mp4\n",
      "Extracted 2082 frames from N:\\shared\\yaojie\\250728-Capture\\views-raw-9\\temp_video_for_share.mp4 to N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_08.\n"
     ]
    }
   ],
   "source": [
    "video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.wmv', '*.flv', '*.webm', '*.m4v', '*.3gp', '*.mpg', '*.mpeg']\n",
    "\n",
    "videos = []\n",
    "for ext in video_extensions:\n",
    "    videos.extend(glob.glob(os.path.join(videos_by_view, ext)))\n",
    "\n",
    "# Sort the videos for consistent ordering\n",
    "videos = sorted(videos)\n",
    "\n",
    "# Print all videos found\n",
    "print(f\"Found {len(videos)} videos:\")\n",
    "for video in videos:\n",
    "    print(video)\n",
    "\n",
    "# Process each video\n",
    "for i, video in enumerate(videos):\n",
    "    print(f\"Processing video {i}/{len(videos)}: {video}\")\n",
    "    output_dir = os.path.join(rgb_sequence_by_view_output, f\"recorded_{i:02d}\")\n",
    "    extract_frames(video, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf1da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_00\n",
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_01\n",
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_02\n",
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_03\n",
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_04\n",
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_05\n",
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_06\n",
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_07\n",
      "Folder: N:\\shared\\yaojie\\250728-Capture\\rgb_sequence_output\\recorded_08\n"
     ]
    }
   ],
   "source": [
    "rgb_sequence_by_view_folders = [d for d in os.listdir(rgb_sequence_by_view_output) if os.path.isdir(os.path.join(rgb_sequence_by_view_output, d))]\n",
    "rgb_sequence_by_view_folders = sorted(rgb_sequence_by_view_folders)\n",
    "rgb_sequence_by_view_folders = [os.path.join(rgb_sequence_by_view_output, folder) for folder in rgb_sequence_by_view_folders]\n",
    "\n",
    "for folder in rgb_sequence_by_view_folders:\n",
    "    print(f\"Folder: {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "844d282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "led_roi = [\n",
    "    [169, 1708],\n",
    "    [456, 1672],\n",
    "    [534, 1892],\n",
    "    [469, 1720],\n",
    "    [794, 1806],\n",
    "    [717, 1630],\n",
    "    [808, 1862],\n",
    "    [668, 1810],\n",
    "    [862, 1402],\n",
    "    [1896, 691],\n",
    "    [1759, 1029],\n",
    "    [1721, 386],\n",
    "    [1831, 767],\n",
    "    [1568, 721],\n",
    "    [1633, 767],\n",
    "    [1894, 721],\n",
    "    [1653, 170]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d35d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "\n",
    "for i, view_folder in enumerate(rgb_sequence_by_view_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(view_folder, ext)))\n",
    "\n",
    "    images = sorted(images)\n",
    "\n",
    "    bframe = detect_hsv_red_change(images, led_roi[i], 1)\n",
    "    print(f\"View {i}: Count: {bframe[1] - bframe[0]}, from({images[bframe[0]]}) to({images[bframe[1]]})\")\n",
    "    for i in range(bframe[0]):\n",
    "        # delete images[i]\n",
    "        os.remove(images[i])\n",
    "\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(view_folder, ext)))\n",
    "\n",
    "    images = sorted(images)\n",
    "    # raname images after removing the first frames name format: 00000.jpg, 00001.jpg, ...\n",
    "    for j, image in enumerate(images):\n",
    "        new_name = f\"{j:05d}.jpg\"\n",
    "        new_path = os.path.join(view_folder, new_name)\n",
    "        os.rename(image, new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_brightness_contrast(reference_image_path):\n",
    "    \"\"\"\n",
    "    Extract brightness and contrast statistics from a reference image\n",
    "    \n",
    "    Parameters:\n",
    "    reference_image_path: path to the reference image\n",
    "    \n",
    "    Returns:\n",
    "    dict containing brightness and contrast data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the reference image\n",
    "    image = cv2.imread(reference_image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to grayscale for global statistics\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate brightness (mean intensity)\n",
    "    target_brightness = np.mean(gray)\n",
    "    \n",
    "    # Calculate contrast (standard deviation)\n",
    "    target_contrast = np.std(gray)\n",
    "    \n",
    "    # Calculate per-channel statistics for color correction\n",
    "    channel_means = [np.mean(image_rgb[:, :, i]) for i in range(3)]\n",
    "    channel_stds = [np.std(image_rgb[:, :, i]) for i in range(3)]\n",
    "    \n",
    "    brightness_contrast_data = {\n",
    "        'target_brightness': target_brightness,\n",
    "        'target_contrast': target_contrast,\n",
    "        'channel_means': channel_means,  # [R, G, B]\n",
    "        'channel_stds': channel_stds,    # [R, G, B]\n",
    "        'reference_image_path': reference_image_path\n",
    "    }\n",
    "    \n",
    "    print(f\"Reference image: {reference_image_path}\")\n",
    "    print(f\"Target brightness: {target_brightness:.2f}\")\n",
    "    print(f\"Target contrast: {target_contrast:.2f}\")\n",
    "    print(f\"Channel means (R,G,B): [{channel_means[0]:.2f}, {channel_means[1]:.2f}, {channel_means[2]:.2f}]\")\n",
    "    print(f\"Channel stds (R,G,B): [{channel_stds[0]:.2f}, {channel_stds[1]:.2f}, {channel_stds[2]:.2f}]\")\n",
    "    \n",
    "    return brightness_contrast_data\n",
    "\n",
    "def apply_brightness_contrast(input_image_path, brightness_contrast_data):\n",
    "    \"\"\"\n",
    "    Apply brightness and contrast correction to match reference image and replace the original\n",
    "    \n",
    "    Parameters:\n",
    "    input_image_path: path to the image to be corrected (will be replaced)\n",
    "    brightness_contrast_data: data extracted from reference image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the input image\n",
    "    image = cv2.imread(input_image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get target values\n",
    "    target_brightness = brightness_contrast_data['target_brightness']\n",
    "    target_contrast = brightness_contrast_data['target_contrast']\n",
    "    target_means = brightness_contrast_data['channel_means']\n",
    "    target_stds = brightness_contrast_data['channel_stds']\n",
    "    \n",
    "    # Calculate current image statistics\n",
    "    current_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    current_brightness = np.mean(current_gray)\n",
    "    current_contrast = np.std(current_gray)\n",
    "    \n",
    "    current_means = [np.mean(image_rgb[:, :, i]) for i in range(3)]\n",
    "    current_stds = [np.std(image_rgb[:, :, i]) for i in range(3)]\n",
    "    \n",
    "    # Create corrected image\n",
    "    corrected_image = image_rgb.copy().astype(np.float32)\n",
    "    \n",
    "    # Apply correction to each channel\n",
    "    for channel in range(3):\n",
    "        if current_stds[channel] > 0:  # Avoid division by zero\n",
    "            # Normalize current channel to have mean=0, std=1\n",
    "            corrected_image[:, :, channel] = (corrected_image[:, :, channel] - current_means[channel]) / current_stds[channel]\n",
    "            \n",
    "            # Scale to target std and shift to target mean\n",
    "            corrected_image[:, :, channel] = corrected_image[:, :, channel] * target_stds[channel] + target_means[channel]\n",
    "    \n",
    "    # Clip values to valid range [0, 255]\n",
    "    corrected_image = np.clip(corrected_image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert back to BGR for saving\n",
    "    corrected_bgr = cv2.cvtColor(corrected_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Replace the original image\n",
    "    cv2.imwrite(input_image_path, corrected_bgr)\n",
    "    \n",
    "    # Print statistics\n",
    "    corrected_gray = cv2.cvtColor(corrected_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    final_brightness = np.mean(corrected_gray)\n",
    "    final_contrast = np.std(corrected_gray)\n",
    "    \n",
    "    print(f\"\\nProcessed: {input_image_path}\")\n",
    "    print(f\"Brightness: {current_brightness:.2f} -> {final_brightness:.2f} (Target: {target_brightness:.2f})\")\n",
    "    print(f\"Contrast: {current_contrast:.2f} -> {final_contrast:.2f} (Target: {target_contrast:.2f})\")\n",
    "    print(f\"✓ Original image replaced with corrected version\")\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Step 1: Extract brightness/contrast data from reference image\n",
    "reference_path = r\"C:\\Users\\jeffr\\Desktop\\test\\01416.jpg\"\n",
    "bc_data = extract_brightness_contrast(reference_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "\n",
    "image_paths = []\n",
    "for ext in image_extensions:\n",
    "    image_paths.extend(glob.glob(os.path.join(r\"C:\\Users\\jeffr\\Desktop\\test\", ext)))\n",
    "\n",
    "for img_path in image_paths:\n",
    "    apply_brightness_contrast(img_path, bc_data)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"\\n✓ All images have been processed and replaced with corrected versions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "767dedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training data - first frame\n",
    "\n",
    "frames_by_views = []\n",
    "for i, view_folder in enumerate(rgb_sequence_by_view_folders):\n",
    "    images = []\n",
    "    for ext in image_extensions:\n",
    "        images.extend(glob.glob(os.path.join(view_folder, ext)))\n",
    "\n",
    "    images = sorted(images)\n",
    "    frames_by_views.append(images)\n",
    "\n",
    "first_frame_folder = os.path.join(frames_to_train, \"frame_0\")\n",
    "for i in range(len(frames_by_views)):\n",
    "    move_to_folder(frames_by_views[i][0], first_frame_folder, f\"{i:05d}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a713ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jeffr/.cache\\torch\\hub\\PeterL1n_RobustVideoMatting_master\n",
      "Using cache found in C:\\Users\\jeffr/.cache\\torch\\hub\\PeterL1n_RobustVideoMatting_master\n",
      "c:\\Users\\jeffr\\.conda\\envs\\rvm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1923/1923 [02:50<00:00, 11.29it/s]\n",
      "100%|██████████| 1923/1923 [02:50<00:00, 11.25it/s]\n",
      "100%|██████████| 1923/1923 [02:38<00:00, 12.10it/s]\n",
      "100%|██████████| 1923/1923 [02:22<00:00, 13.46it/s]\n",
      "100%|██████████| 1923/1923 [02:30<00:00, 12.79it/s]\n",
      "100%|██████████| 1923/1923 [02:25<00:00, 13.19it/s]\n",
      "100%|██████████| 1923/1923 [02:33<00:00, 12.57it/s]\n",
      "100%|██████████| 1923/1923 [02:33<00:00, 12.55it/s]\n",
      "100%|██████████| 1923/1923 [02:18<00:00, 13.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove background\n",
    "\n",
    "rvm_path = r\"C:\\Repo\\RobustVideoMatting\"\n",
    "sys.path.append(rvm_path)\n",
    "\n",
    "model = torch.hub.load(\"PeterL1n/RobustVideoMatting\", \"mobilenetv3\").cuda()\n",
    "convert_video = torch.hub.load(\"PeterL1n/RobustVideoMatting\", \"converter\")\n",
    "\n",
    "temp_folder = r\"N:\\shared\\yaojie\\250728-Capture\\temp\"\n",
    "if not os.path.exists(temp_folder):\n",
    "    os.makedirs(temp_folder)\n",
    "\n",
    "frames_by_views = []\n",
    "for i, view_folder in enumerate(rgb_sequence_by_view_folders):\n",
    "    temp_sequence_folder = os.path.join(temp_folder, f\"view_{i:02d}\")\n",
    "    convert_video(\n",
    "        model,                           # The loaded model, can be on any device (cpu or cuda).\n",
    "        input_source=view_folder,        # A video file or an image sequence directory.\n",
    "        downsample_ratio=None,           # [Optional] If None, make downsampled max size be 512px.\n",
    "        output_type='png_sequence',             # Choose \"video\" or \"png_sequence\"\n",
    "        output_composition=temp_sequence_folder,    # File path if video; directory path if png sequence.\n",
    "        #output_alpha=f\"{output}/pha.mp4\",          # [Optional] Output the raw alpha prediction.\n",
    "        #output_foreground=f\"{output}/fgr.mp4\",     # [Optional] Output the raw foreground prediction.\n",
    "        #output_video_mbps=4,             # Output video mbps. Not needed for png sequence.\n",
    "        seq_chunk=15,                    # Process n frames at once for better parallelism.\n",
    "        num_workers=5,                   # Only for image sequence input. Reader threads.\n",
    "        progress=True                    # Print conversion progress.\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
